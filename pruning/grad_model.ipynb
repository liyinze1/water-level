{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d6f82c9-fa7a-4897-bb8b-4b90db789887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b821873",
   "metadata": {},
   "source": [
    "# this notebook is used to test why the model is not providing the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb95b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../scaling\")\n",
    "\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import v2\n",
    "from ultralytics import YOLO\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32444b79-588d-499c-b0a1-7ad2e37f63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import decode_yolov11_segmentation, decode_yolov11_segmentation2\n",
    "from evaluate import combine_masks, decode_raw_labels\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import WaterLevelDataset, collate_fn\n",
    "from evaluate import create_binary_mask\n",
    "from matplotlib.patches import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dc48fb5-512f-45bd-ae48-dc1fa2ad1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c380f2",
   "metadata": {},
   "source": [
    "# definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89e92c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../water.yaml\n"
     ]
    }
   ],
   "source": [
    "base_folder = os.path.dirname(os.curdir)\n",
    "imgsz = 640  # the default on train.py\n",
    "best_model_path = os.path.join(base_folder, \"../runs/segment/yolo11l-seg-300ep/weights/best.pt\")\n",
    "config_file = os.path.join(base_folder, \"../water.yaml\")\n",
    "\n",
    "# configuration file\n",
    "print(f\"Reading {config_file}\")\n",
    "with open(config_file, 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0477cff6-db0e-41ae-a8ec-6676b597e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "imgsz = 640\n",
    "transform = v2.Compose([\n",
    "    v2.Resize([imgsz, imgsz]),  # we need to resize both h and w\n",
    "    # v2.ToTensor()  # deprecated, use the line below\n",
    "    v2.ToImage(), v2.ToDtype(torch.float32, scale=True)  # notice that v2.ToImage converts to [0.0, 1.0]\n",
    "])\n",
    "\n",
    "dataset = WaterLevelDataset(config_path=config_file, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)  \n",
    "inputs, targets = next(iter(data_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aadf43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode input into a mask\n",
    "target_mask = create_binary_mask(targets, imgsz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bc07330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best YOLO model\n",
    "yolo_model = YOLO(best_model_path)\n",
    "model = yolo_model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099308d1-9cce-4734-bb56-b1c7d9de6d6e",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "\n",
    "- check the output structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cebc0d2-c7bd-4dfd-b1e8-fce6a62ae0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(model, where=\"\"):\n",
    "    if len(where.strip()) > 0:\n",
    "        print(where)\n",
    "    modules = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            modules.append(name)\n",
    "    if len(modules) > 0:\n",
    "        if len(modules) < 10:\n",
    "            print(\"ðŸ›‡\", \",\".join(modules))\n",
    "        else:\n",
    "            print(\"ðŸ›‡ðŸ›‡ðŸ›‡ Too many modules to list =\",len(modules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8aa4f357-1e1d-453c-835f-f99750554ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = True\n",
    "    if not param.requires_grad:\n",
    "        print(\"ðŸ›‡\", name)    \n",
    "    # print(name, \"ðŸ‘Œrequires\"  else \"ðŸ›‡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35963f8a-4078-4682-92dc-145659d9018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77cf6fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before .train()\n",
      "before zero_grad\n",
      "before model(inputs)\n",
      "after optimizer\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "check(model, \"before .train()\")\n",
    "model.train()  # when this method is called, the parameters become \n",
    "check(model, \"before zero_grad\")\n",
    "optimizer.zero_grad()\n",
    "check(model, \"before model(inputs)\")\n",
    "outputs = model(inputs)  # (B, C, H, W)\n",
    "boxes, masks = decode_yolov11_segmentation2(outputs)\n",
    "\n",
    "pred_mask = combine_masks(masks)\n",
    "\n",
    "# Compute the loss and its gradients\n",
    "loss = loss_fn(pred_mask, target_mask)\n",
    "loss.backward()\n",
    "# optimizer.step()\n",
    "check(model, \"after optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b4bc291-e2be-41dd-97b9-65e9702975e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many parameters don't have grad to list. Total = 67/291\n"
     ]
    }
   ],
   "source": [
    "no_grad = []\n",
    "num_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        num_params += 1\n",
    "        if param.grad is None:\n",
    "            no_grad.append(name)\n",
    "if len(no_grad) == 0:\n",
    "    print(\"all parameter have grad\")\n",
    "elif len(no_grad) < 10:\n",
    "    print(f\"Only {no_grad} don't have grad\")\n",
    "else:\n",
    "    print(f\"Too many parameters don't have grad to list. Total = {len(no_grad)}/{num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8294f02c-c2a1-4e42-9c72-2f3de6a713b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after check grad field\n"
     ]
    }
   ],
   "source": [
    "check(model, \"after check grad field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cc2e0f4-aec8-4e2c-b6bd-2c22686065d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "457bed1d-dd43-4c86-a9c2-6e0aa88d0790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model[0].conv.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3e092fc-be6e-459f-9932-1e37cca03163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-8.3269), tensor(7.2993))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model[0].conv.weight.grad.min(), model.model[0].conv.weight.grad.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
